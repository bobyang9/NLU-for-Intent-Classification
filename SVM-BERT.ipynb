{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from load_data import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(config):\n",
    "    save_dir = Path('embeddings/snips_bert_encodings')\n",
    "    save_dir = save_dir / config\n",
    "    X_train = np.load(save_dir / 'X_train.npy')\n",
    "    y_train = np.load(save_dir / 'y_train.npy')\n",
    "    X_valid = np.load(save_dir / 'X_valid.npy')\n",
    "    y_valid = np.load(save_dir / 'y_valid.npy')\n",
    "    X_test = np.load(save_dir / 'X_test.npy')\n",
    "    y_test = np.load(save_dir / 'y_test.npy')\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(config)\n",
    "    print(\"accuracy_train: \", clf.score(X_train, y_train))\n",
    "    print(\"accuracy_val: \", clf.score(X_valid, y_valid))\n",
    "    f1_score_train = sklearn.metrics.f1_score(y_train, clf.predict(X_train), average = 'weighted')\n",
    "    f1_score_val = sklearn.metrics.f1_score(y_valid, clf.predict(X_valid), average = 'weighted')\n",
    "    print(\"f1_score_train: \", f1_score_train)\n",
    "    print(\"f1_score_val: \", f1_score_val)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n",
      "accuracy_train:  0.9919810600274935\n",
      "accuracy_val:  0.9753623188405797\n",
      "f1_score_train:  0.9919905634187017\n",
      "f1_score_val:  0.9754029791230946\n",
      "\n",
      "distilbert-base-uncased\n",
      "accuracy_train:  0.9922101725981366\n",
      "accuracy_val:  0.981159420289855\n",
      "f1_score_train:  0.9922146913308851\n",
      "f1_score_val:  0.9811611573290838\n",
      "\n",
      "roberta-base\n",
      "accuracy_train:  0.994424927447686\n",
      "accuracy_val:  0.9768115942028985\n",
      "f1_score_train:  0.9944265411429662\n",
      "f1_score_val:  0.9768813296529276\n",
      "\n",
      "google/electra-small-discriminator\n",
      "accuracy_train:  0.9763250343668856\n",
      "accuracy_val:  0.9231884057971015\n",
      "f1_score_train:  0.9763406750066445\n",
      "f1_score_val:  0.9232614013634802\n",
      "\n",
      "bert-base-nli-mean-tokens\n",
      "accuracy_train:  0.9919810600274935\n",
      "accuracy_val:  0.9782608695652174\n",
      "f1_score_train:  0.991986995935476\n",
      "f1_score_val:  0.9782588281867504\n",
      "\n",
      "bert-large-nli-mean-tokens\n",
      "accuracy_train:  0.9913700931724454\n",
      "accuracy_val:  0.9666666666666667\n",
      "f1_score_train:  0.9913743250984816\n",
      "f1_score_val:  0.9667933330218647\n",
      "\n",
      "bert-base-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9934321063082328\n",
      "accuracy_val:  0.9652173913043478\n",
      "f1_score_train:  0.9934345367559103\n",
      "f1_score_val:  0.9650977281126694\n",
      "\n",
      "bert-large-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9935848480219948\n",
      "accuracy_val:  0.9565217391304348\n",
      "f1_score_train:  0.9935803241812623\n",
      "f1_score_val:  0.9566156314421473\n",
      "\n",
      "distilbert-base-nli-mean-tokens\n",
      "accuracy_train:  0.9908354971742783\n",
      "accuracy_val:  0.972463768115942\n",
      "f1_score_train:  0.9908386727036868\n",
      "f1_score_val:  0.972550660251544\n",
      "\n",
      "distilbert-base-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9941958148770429\n",
      "accuracy_val:  0.9652173913043478\n",
      "f1_score_train:  0.9941960285365707\n",
      "f1_score_val:  0.965162723547627\n",
      "\n",
      "roberta-base-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9911409806018023\n",
      "accuracy_val:  0.9666666666666667\n",
      "f1_score_train:  0.9911453496681775\n",
      "f1_score_val:  0.9666360790427275\n",
      "\n",
      "roberta-large-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9922101725981366\n",
      "accuracy_val:  0.9623188405797102\n",
      "f1_score_train:  0.9922113496200252\n",
      "f1_score_val:  0.9622706649198154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for config in HUGGING_FACE_PRETRAINED_MODELS:\n",
    "    train_svm(config)\n",
    "for config in SBERT_PRETRAINED_MODELS:\n",
    "    train_svm(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATIS (mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(config):\n",
    "    save_dir = Path('embeddings/atis_bert_encodings')\n",
    "    save_dir = save_dir / config\n",
    "    X_train = np.load(save_dir / 'X_train.npy')\n",
    "    y_train = np.load(save_dir / 'y_train.npy')\n",
    "    X_valid = np.load(save_dir / 'X_valid.npy')\n",
    "    y_valid = np.load(save_dir / 'y_valid.npy')\n",
    "    X_test = np.load(save_dir / 'X_test.npy')\n",
    "    y_test = np.load(save_dir / 'y_test.npy')\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(config)\n",
    "    print(\"accuracy_train: \", clf.score(X_train, y_train))\n",
    "    print(\"accuracy_val: \", clf.score(X_valid, y_valid))\n",
    "    f1_score_train = sklearn.metrics.f1_score(y_train, clf.predict(X_train), average = 'weighted')\n",
    "    f1_score_val = sklearn.metrics.f1_score(y_valid, clf.predict(X_valid), average = 'weighted')\n",
    "    print(\"f1_score_train: \", f1_score_train)\n",
    "    print(\"f1_score_val: \", f1_score_val)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n",
      "accuracy_train:  0.9873693379790941\n",
      "accuracy_val:  0.9462809917355371\n",
      "f1_score_train:  0.9867946407117943\n",
      "f1_score_val:  0.9349680622407895\n",
      "\n",
      "distilbert-base-uncased\n",
      "accuracy_train:  0.9867160278745645\n",
      "accuracy_val:  0.9628099173553719\n",
      "f1_score_train:  0.9857176308433813\n",
      "f1_score_val:  0.9568141197497767\n",
      "\n",
      "roberta-base\n",
      "accuracy_train:  0.9895470383275261\n",
      "accuracy_val:  0.9669421487603306\n",
      "f1_score_train:  0.9890349269616012\n",
      "f1_score_val:  0.9631681806144972\n",
      "\n",
      "google/electra-small-discriminator\n",
      "accuracy_train:  0.9636324041811847\n",
      "accuracy_val:  0.9214876033057852\n",
      "f1_score_train:  0.9604413158079286\n",
      "f1_score_val:  0.9118949034982741\n",
      "\n",
      "bert-base-nli-mean-tokens\n",
      "accuracy_train:  0.9729965156794426\n",
      "accuracy_val:  0.9380165289256198\n",
      "f1_score_train:  0.969413018219214\n",
      "f1_score_val:  0.9283219134415306\n",
      "\n",
      "bert-large-nli-mean-tokens\n",
      "accuracy_train:  0.975609756097561\n",
      "accuracy_val:  0.9669421487603306\n",
      "f1_score_train:  0.9711837389967062\n",
      "f1_score_val:  0.9594311996395838\n",
      "\n",
      "bert-base-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.975609756097561\n",
      "accuracy_val:  0.9380165289256198\n",
      "f1_score_train:  0.9719862019820612\n",
      "f1_score_val:  0.9275090899014343\n",
      "\n",
      "bert-large-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9753919860627178\n",
      "accuracy_val:  0.9462809917355371\n",
      "f1_score_train:  0.9716787224983127\n",
      "f1_score_val:  0.9359585428345758\n",
      "\n",
      "distilbert-base-nli-mean-tokens\n",
      "accuracy_train:  0.9749564459930313\n",
      "accuracy_val:  0.9462809917355371\n",
      "f1_score_train:  0.9705590738387023\n",
      "f1_score_val:  0.9372305008668645\n",
      "\n",
      "distilbert-base-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9782229965156795\n",
      "accuracy_val:  0.9297520661157025\n",
      "f1_score_train:  0.974109252973804\n",
      "f1_score_val:  0.9181542699724518\n",
      "\n",
      "roberta-base-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9734320557491289\n",
      "accuracy_val:  0.9504132231404959\n",
      "f1_score_train:  0.9696635922298534\n",
      "f1_score_val:  0.9378623305069587\n",
      "\n",
      "roberta-large-nli-stsb-mean-tokens\n",
      "accuracy_train:  0.9797473867595818\n",
      "accuracy_val:  0.9545454545454546\n",
      "f1_score_train:  0.9778597968711498\n",
      "f1_score_val:  0.945085536834906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for config in HUGGING_FACE_PRETRAINED_MODELS:\n",
    "    train_svm(config)\n",
    "for config in SBERT_PRETRAINED_MODELS:\n",
    "    train_svm(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
