{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './atis/atis_train_actual.csv'\n",
    "TEST_PATH = './atis/atis_test_actual.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = SnipsDataLoader(train_path=TRAIN_PATH, valid_path=None, test_path=TEST_PATH)\n",
    "data_loader.split_train_valid(valid_size=0.05, keep_class_ratios=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_loader.get_train_data()\n",
    "X_valid, y_valid = data_loader.get_valid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(X_train, X_valid)\n",
    "feature_extractor.extract_features(keep_words_threshold=5)\n",
    "X_train = feature_extractor.get_train_encodings()\n",
    "X_valid = feature_extractor.get_valid_encodings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_examples, vocab_size = X.shape\n",
    "        num_labels = np.amax(y) + 1\n",
    "        y_one_hot = np.eye(num_labels)[y]\n",
    "        X_row_sum = np.sum(X, axis=1, keepdims=True)\n",
    "        \n",
    "        self.vocab_probs = (1 + np.dot(X.T, y_one_hot)) / (vocab_size + np.dot(X_row_sum.T, y_one_hot))\n",
    "        self.prior_probs = np.mean(y_one_hot, axis=0)\n",
    "        self.vocab_log_probs = np.log(self.vocab_probs)\n",
    "        self.prior_log_probs = np.log(self.prior_probs)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        post_probs = np.dot(X, self.vocab_log_probs) + self.prior_log_probs\n",
    "        predictions = np.argmax(post_probs, axis=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, targets):\n",
    "    return np.mean(predictions == targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9256198347107438"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_valid)\n",
    "calculate_accuracy(y_predict, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
