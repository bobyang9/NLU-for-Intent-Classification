{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from load_data import *\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './snips/snips_train_actual.csv'\n",
    "TEST_PATH = './snips/snips_test_actual.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = SnipsDataLoader(TRAIN_PATH, None, TEST_PATH)\n",
    "data_loader.split_train_valid(valid_size=0.05, keep_class_ratios=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_loader.get_train_data()\n",
    "X_valid, y_valid = data_loader.get_valid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(X_train, X_valid)\n",
    "feature_extractor.extract_features(keep_words_threshold=5)\n",
    "X_train = feature_extractor.get_train_encodings()\n",
    "X_valid = feature_extractor.get_valid_encodings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression():\n",
    "    def __init__(self, training_rate, num_iter):\n",
    "        self.training_rate = training_rate\n",
    "        self.num_iter = num_iter\n",
    "        pass\n",
    "    \n",
    "    \"\"\"\n",
    "    fit(self, X, y): fits the weights and biases based on X (training set design matrix) and y (training set ground truths).\n",
    "    Input: X -- (num_examples, vocab_size) shape.\n",
    "    Input: y -- (num_examples, ) shape.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "        num_examples, vocab_size = X.shape\n",
    "        num_labels = np.amax(y) + 1\n",
    "        y_one_hot = np.eye(num_labels)[y].T\n",
    "        y_val_one_hot = np.eye(num_labels)[y_val].T\n",
    "        \n",
    "        self.weights = np.random.normal(loc=0.0, scale=(1/np.sqrt(X.shape[0])), size=(num_labels, vocab_size))\n",
    "        self.biases = np.zeros((num_labels,1))\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            predictions = self.predict(X)\n",
    "            self.weights = self.weights - self.training_rate * np.dot(predictions - y_one_hot, X)\n",
    "            self.biases = self.biases - self.training_rate * np.reshape(np.sum(predictions - y_one_hot, axis=1), (-1, 1))\n",
    "            predictions_train = self.predict(X)\n",
    "            predictions_val = self.predict(X_val)\n",
    "            train_loss = self.get_loss(predictions_train, y_one_hot)\n",
    "            val_loss = self.get_loss(predictions_val, y_val_one_hot)\n",
    "            train_accuracy = self.find_accuracy(predictions_train, y)\n",
    "            val_accuracy = self.find_accuracy(predictions_val, y_val)\n",
    "            if(i%5 == 0):\n",
    "                print(\"Iteration %d: train_loss: %f, val_loss: %f, train_accuracy: %f, val_accuracy: %f\"%(i, train_loss, val_loss, train_accuracy, val_accuracy))   \n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    predict(self, X): Returns predictions of the labels given the design matrix X.\n",
    "    Input: X -- (num_examples, vocab_size) shape.\n",
    "    Output: predictions -- (num_labels, num_examples) shape.\n",
    "    \"\"\"\n",
    "    def predict(self, X):\n",
    "        return scipy.special.softmax(np.dot(self.weights, X.T) + self.biases, axis=0)\n",
    "    \n",
    "    \"\"\"\n",
    "    get_loss(self, X, y): Returns the loss.\n",
    "    Input: predictions -- (num_examples, num_labels) shape.\n",
    "    Input: y -- (num_examples, num_labels) shape. (has to be one-hot)\n",
    "    Output: loss -- scalar.\n",
    "    \"\"\"\n",
    "    def get_loss(self, predictions, y):\n",
    "        return -np.average(np.sum(np.multiply(y, np.log(predictions)), axis=0))\n",
    "    \n",
    "    \"\"\"\n",
    "    find_accuracy(self, predictions, y): returns the accuracy\n",
    "    Input: predictions -- (num_examples, num_labels) shape.\n",
    "    Input: y -- (num_examples, num_labels) shape. (has to be one-hot)\n",
    "    Output: loss -- scalar.\n",
    "    \"\"\"\n",
    "    def find_accuracy(self, predictions, y):\n",
    "        predictions = np.argmax(predictions, axis=0)\n",
    "        return np.average(predictions==y)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: train_loss: 0.656036, val_loss: 0.656886, train_accuracy: 0.855888, val_accuracy: 0.840580\n",
      "Iteration 5: train_loss: 0.329867, val_loss: 0.341177, train_accuracy: 0.905606, val_accuracy: 0.905797\n",
      "Iteration 10: train_loss: 0.181788, val_loss: 0.184558, train_accuracy: 0.960669, val_accuracy: 0.962319\n",
      "Iteration 15: train_loss: 0.154401, val_loss: 0.157129, train_accuracy: 0.965709, val_accuracy: 0.966667\n",
      "Iteration 20: train_loss: 0.137029, val_loss: 0.140026, train_accuracy: 0.968535, val_accuracy: 0.971014\n",
      "Iteration 25: train_loss: 0.124700, val_loss: 0.128031, train_accuracy: 0.971055, val_accuracy: 0.972464\n",
      "Iteration 30: train_loss: 0.115364, val_loss: 0.119045, train_accuracy: 0.973347, val_accuracy: 0.973913\n",
      "Iteration 35: train_loss: 0.107975, val_loss: 0.112007, train_accuracy: 0.974798, val_accuracy: 0.975362\n",
      "Iteration 40: train_loss: 0.101937, val_loss: 0.106314, train_accuracy: 0.976478, val_accuracy: 0.979710\n",
      "Iteration 45: train_loss: 0.096880, val_loss: 0.101595, train_accuracy: 0.977929, val_accuracy: 0.979710\n",
      "Iteration 50: train_loss: 0.092563, val_loss: 0.097609, train_accuracy: 0.978845, val_accuracy: 0.982609\n",
      "Iteration 55: train_loss: 0.088820, val_loss: 0.094189, train_accuracy: 0.979685, val_accuracy: 0.984058\n",
      "Iteration 60: train_loss: 0.085533, val_loss: 0.091217, train_accuracy: 0.980678, val_accuracy: 0.984058\n",
      "Iteration 65: train_loss: 0.082614, val_loss: 0.088608, train_accuracy: 0.980984, val_accuracy: 0.984058\n",
      "Iteration 70: train_loss: 0.079999, val_loss: 0.086295, train_accuracy: 0.981824, val_accuracy: 0.984058\n",
      "Iteration 75: train_loss: 0.077637, val_loss: 0.084230, train_accuracy: 0.982358, val_accuracy: 0.984058\n",
      "Iteration 80: train_loss: 0.075490, val_loss: 0.082373, train_accuracy: 0.982969, val_accuracy: 0.985507\n",
      "Iteration 85: train_loss: 0.073525, val_loss: 0.080693, train_accuracy: 0.983428, val_accuracy: 0.985507\n",
      "Iteration 90: train_loss: 0.071719, val_loss: 0.079166, train_accuracy: 0.983886, val_accuracy: 0.986957\n",
      "Iteration 95: train_loss: 0.070050, val_loss: 0.077770, train_accuracy: 0.984344, val_accuracy: 0.986957\n"
     ]
    }
   ],
   "source": [
    "sr = SoftmaxRegression(0.001, 100)\n",
    "sr.fit(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "test3 = np.array([3, 5, 1])\n",
    "test4 = np.array([2, 5, 1])\n",
    "print(np.average(test3 == test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1, 2], [3, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test == test.max(axis=0, keepdims=1)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = np.array([[1, 9, 5], [3, 2, 8], [4, 6, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: train_loss: 0.652334, val_loss: 0.652889\n",
      "Iteration 5: train_loss: 0.327224, val_loss: 0.339007\n",
      "Iteration 10: train_loss: 0.182011, val_loss: 0.184780\n",
      "Iteration 15: train_loss: 0.154580, val_loss: 0.157310\n",
      "Iteration 20: train_loss: 0.137163, val_loss: 0.140156\n",
      "Iteration 25: train_loss: 0.124806, val_loss: 0.128132\n",
      "Iteration 30: train_loss: 0.115451, val_loss: 0.119129\n",
      "Iteration 35: train_loss: 0.108049, val_loss: 0.112080\n",
      "Iteration 40: train_loss: 0.102001, val_loss: 0.106380\n",
      "Iteration 45: train_loss: 0.096936, val_loss: 0.101657\n",
      "Iteration 50: train_loss: 0.092613, val_loss: 0.097667\n",
      "Iteration 55: train_loss: 0.088865, val_loss: 0.094245\n",
      "Iteration 60: train_loss: 0.085574, val_loss: 0.091272\n",
      "Iteration 65: train_loss: 0.082652, val_loss: 0.088662\n",
      "Iteration 70: train_loss: 0.080034, val_loss: 0.086350\n",
      "Iteration 75: train_loss: 0.077670, val_loss: 0.084285\n",
      "Iteration 80: train_loss: 0.075521, val_loss: 0.082428\n",
      "Iteration 85: train_loss: 0.073555, val_loss: 0.080749\n",
      "Iteration 90: train_loss: 0.071747, val_loss: 0.079222\n",
      "Iteration 95: train_loss: 0.070077, val_loss: 0.077827\n",
      "Iteration 100: train_loss: 0.068527, val_loss: 0.076547\n",
      "Iteration 105: train_loss: 0.067083, val_loss: 0.075368\n",
      "Iteration 110: train_loss: 0.065734, val_loss: 0.074278\n",
      "Iteration 115: train_loss: 0.064469, val_loss: 0.073267\n",
      "Iteration 120: train_loss: 0.063279, val_loss: 0.072326\n",
      "Iteration 125: train_loss: 0.062158, val_loss: 0.071449\n",
      "Iteration 130: train_loss: 0.061098, val_loss: 0.070628\n",
      "Iteration 135: train_loss: 0.060094, val_loss: 0.069860\n",
      "Iteration 140: train_loss: 0.059142, val_loss: 0.069137\n",
      "Iteration 145: train_loss: 0.058236, val_loss: 0.068457\n",
      "Iteration 150: train_loss: 0.057373, val_loss: 0.067816\n",
      "Iteration 155: train_loss: 0.056550, val_loss: 0.067210\n",
      "Iteration 160: train_loss: 0.055763, val_loss: 0.066637\n",
      "Iteration 165: train_loss: 0.055011, val_loss: 0.066093\n",
      "Iteration 170: train_loss: 0.054289, val_loss: 0.065577\n",
      "Iteration 175: train_loss: 0.053597, val_loss: 0.065087\n",
      "Iteration 180: train_loss: 0.052933, val_loss: 0.064620\n",
      "Iteration 185: train_loss: 0.052293, val_loss: 0.064176\n",
      "Iteration 190: train_loss: 0.051678, val_loss: 0.063751\n",
      "Iteration 195: train_loss: 0.051085, val_loss: 0.063346\n"
     ]
    }
   ],
   "source": [
    "sr = SoftmaxRegression(0.001, 200)\n",
    "sr.fit(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.         -0.         -0.51082562 -0.         -0.         -0.\n",
      " -0.        ]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([0, 0, 1, 0, 0, 0, 0])\n",
    "x = np.array([0.1, 0.1, 0.6, 0.1, 0.1, 0.1, 0.1])\n",
    "print(np.multiply(y, np.log(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 * log(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 13094)\n",
      "(7, 13094)\n",
      "(13094, 1641)\n"
     ]
    }
   ],
   "source": [
    "sr = SoftmaxRegression()\n",
    "sr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 5]]\n"
     ]
    }
   ],
   "source": [
    "test1 = np.array([[1, 2], [3, 5]])\n",
    "print(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11920292, 0.04742587],\n",
       "       [0.88079708, 0.95257413]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.special.softmax(test1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
